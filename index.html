<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="禁鱼之地，塘主勿扰">
<meta property="og:type" content="website">
<meta property="og:title" content="特大号鲨鱼的池塘">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="特大号鲨鱼的池塘">
<meta property="og:description" content="禁鱼之地，塘主勿扰">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="特大号的研究僧">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>特大号鲨鱼的池塘</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">特大号鲨鱼的池塘</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">4</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">2</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">5</span></a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/05/21/TTE-RL-schedule/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/header.png">
      <meta itemprop="name" content="特大号的研究僧">
      <meta itemprop="description" content="禁鱼之地，塘主勿扰">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="特大号鲨鱼的池塘">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/05/21/TTE-RL-schedule/" class="post-title-link" itemprop="url">TTE_RL_schedule</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-05-21 19:56:58" itemprop="dateCreated datePublished" datetime="2021-05-21T19:56:58+08:00">2021-05-21</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/05/14/Q-learning-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/header.png">
      <meta itemprop="name" content="特大号的研究僧">
      <meta itemprop="description" content="禁鱼之地，塘主勿扰">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="特大号鲨鱼的池塘">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/05/14/Q-learning-1/" class="post-title-link" itemprop="url">Q-learning</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-05-14 18:13:20 / 修改时间：19:30:57" itemprop="dateCreated datePublished" datetime="2021-05-14T18:13:20+08:00">2021-05-14</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">强化学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="什么是强化学习"><a href="#什么是强化学习" class="headerlink" title="什么是强化学习"></a>什么是强化学习</h1><p><img src="https://www.novatec-gmbh.de/wp-content/uploads/1_mPGk9WTNNvp3i4-9JFgD3w.png" alt="强化学习"></p>
<p>举一个很简单的例子，如果你养了一只宠物—旺财，旺财是一只刚出生的宠物（不一定是狗），啥也不知道，纯洁的像一张白纸。现在你想训练它达到一个目的，例如你想让旺财学猫叫。那么如果旺财“喵”了一声，你就给它最喜欢吃的骨头。如果它“旺”了一声，不仅没有骨头吃，还要严厉的惩罚。久而久之，旺财知道了，喵=骨头，汪=惩罚。</p>
<p>我们作为主人来模仿环境，例如以命令的形式给我们的旺财一个状态St。我们的旺财是接收状态的对象，随即采取类似喵或者汪的动作。旺财选择任一种动作的过程叫做决策。我们对旺财进行奖励或者惩罚称为赏罚（reward有好有坏），如此循环。</p>
<h1 id="什么是Q-learning"><a href="#什么是Q-learning" class="headerlink" title="什么是Q-learning"></a>什么是Q-learning</h1><p>Q-learning其实就是把上述那些过程用一个Q表的形式表示出来而已。</p>
<p>在了解什么是Q表之前，我们先说明一下简称，<strong>S，R，A分别表示当前的状态，奖励，动作；S_，R_，A_分别表示下一状态，奖励，动作</strong>。</p>
<p>首先对一个Q表进行初始化（这里面的值可以全为0，或者随机）</p>
<table>
<thead>
<tr>
<th align="center">（空）</th>
<th align="center">a1</th>
<th align="center">a2</th>
</tr>
</thead>
<tbody><tr>
<td align="center">s1</td>
<td align="center">-2</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">s2</td>
<td align="center">-4</td>
<td align="center">1</td>
</tr>
</tbody></table>
<h1 id="Q-learning举例分析"><a href="#Q-learning举例分析" class="headerlink" title="Q-learning举例分析"></a>Q-learning举例分析</h1><p>假设我们当前状态S = s1，此时我们需要作出动作A，可以选择的动作有a1和a2，现在我们有一个Q值表（这个只是一个大概的，并不是最终的Q值，我们的目的就是修改这一个Q值表，得到一个准确的数据），如果作出a1动作，我们内心大概估计得到的Q值为-2，如果作出a2动作，会得到Q值为1（这里我们认为Q值越大，代表的结果越好）。</p>
<p>那么我们果断作出a2的动作（注意，有时候尽管某一个Q值很大，但是有些人会存在逆反心理，就是要选择小的，所以这里存在一定的概念选择a1）。我们假设选择了a2动作，碰巧我们的s1做完a2动作后进入s2的状态，只有我们进入s2状态后才知道到底是奖励还是惩罚，设为R。<br>刚刚这样的一轮操作已经完成了一次强化学习的过程，那么学习体现在哪呢？</p>
<p>之前我们提到过，我们的目的是对Q值表进行更新，对Q表的更新就是一次学习的过程，我们在s1状态下作出了a1的动作，就能学习到这一次过程的好坏，为了以后我们在所有状态都能作出最好的动作而得到奖励。</p>
<h1 id="Q-learning-更新"><a href="#Q-learning-更新" class="headerlink" title="Q-learning 更新"></a>Q-learning 更新</h1><p><strong>接下来是真正的重点</strong></p>
<p><img src="https://static.mofanpy.com/results/ML-intro/q3.png" alt="Q更新"></p>
<p>前面提到了，我们在s1状态下作出了a1的动作，就能学习到这一次过程的好坏，那么我们就应该更新Q表中（s1，a2）的Q值。设当前表格中的Q（s1，a1）=1表示为Q_eval(我们叫它Q估计，因为这是我们在经过一次学习过程之前的Q值，可能是对的也可能是错的，所以叫它Q估计)，而经过一次学习之后，我们有了这次动作得到的奖励R，以及下一个状态s2，如何利用好这两个条件来估计得到对于（s1，a2）这个动作的Q呢。毋庸置疑R越大，肯定Q越大，所以R肯定独占一项；那S2状态就一点用都没有吗，答案肯定是否认的。我们可以利用Q表中s2的关于所有的动作的值，选择其中最大的那个（也就是表中的（s2，a2）），乘上一个衰减系数gamma（这里我的理解是，虽然Q并不是奖励R，但是在我们心中，认为Q值越大那么和大的奖励值相关性越强，也更能说明我们在s1作出a2动作的好处，加上一个系数更方便我们调节），这也就是我们的第二项。</p>
<p>我们将上述两项加在一起，称为Q_target(Q目标值)。有了Q_eval和Q_target，将两者做差值，再乘上一个学习率alpha，最后加上原来的Q（也就是Q_eval），就算更新完了一次Q表中的Q（s1，a2）。</p>
<p>之后的过程就是循环多次学习，更新整个Q值表，使其更加贴切现实环境，能够更快的拿到想要的奖励。</p>
<h1 id="Q-learning决策"><a href="#Q-learning决策" class="headerlink" title="Q-learning决策"></a>Q-learning决策</h1><p>在Q-learning中我们忽略一个重要的内容，就是决策（如何选择动作a）。</p>
<p>之前可能提过Q值越大间接表示了可能离奖励越近，但是Q并不等于R。如果我们在s1状态的时候选择大Q值得动作，如果a2真的能将我们更好的得到奖励，那肯定是很好的；但是我们要知道，最开始的时候，我们对于这个环境是一点都不了解的，初始的Q值表是随机生成的（也可能全是0），所以不能完全用最大Q值来决定我们的下一步动作，也需要留一点余地，给出一个小概率，让模型选择一个非常之路，没准非常之路更好更快。</p>
<p><img src="https://static.mofanpy.com/results/reinforcement-learning/2-1-1.png" alt="Qlearning算法"></p>
<p>因为在初始阶段, 随机的探索环境, 往往比固定的行为模式要好, 所以这也是累积经验的阶段, 我们希望探索者不会那么贪婪(greedy). 所以 EPSILON 就是用来控制贪婪程度的值. EPSILON 可以随着探索时间不断提升(越来越贪婪)。</p>
<pre><code>`python编码
&#39;# 在某个 state 地点, 选择行为
def choose_action(state, q_table):`
    state_actions = q_table.iloc[state, :]  # 选出这个 state 的所有 action 值
    if (np.random.uniform() &gt; EPSILON) or (state_actions.all() == 0):  # 非贪婪 or 或者这个 state 还没有探索过
        action_name = np.random.choice(ACTIONS)
    else:
        action_name = state_actions.argmax()    # 贪婪模式
    return action_name`
</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/05/08/DQN-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/header.png">
      <meta itemprop="name" content="特大号的研究僧">
      <meta itemprop="description" content="禁鱼之地，塘主勿扰">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="特大号鲨鱼的池塘">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/05/08/DQN-2/" class="post-title-link" itemprop="url">DQN(Deep Q Network)---（2）</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-05-08 11:41:04 / 修改时间：17:50:30" itemprop="dateCreated datePublished" datetime="2021-05-08T11:41:04+08:00">2021-05-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">强化学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="续DQN"><a href="#续DQN" class="headerlink" title="续DQN"></a>续DQN</h1><p><img src="https://mofanpy.com/static/results/reinforcement-learning/4-3-2.png" alt="graph"></p>
<p>上图为整个神经网络的结构图，很明显可以看到神经网络包含2个网络结构—target_net和eval_net。</p>
<p>eval_net是一个实时神经网络，每次进行强化学习的过程，它的参数都会更新训练，所以它是一个实时神经网络。</p>
<p>target_net是一个延迟神经网络，它的网络结构和eval_net是一样的，但是参数更新相对于eval_net是延后的，例如可能在eval_net进行200次的更新后，target_net才更新一次，这一次更新就是将此时的eval_net的参数赋值给target_net。</p>
<p>关于神经网络训练的内容则需要查看其他资料。</p>
<h1 id="Double-DQN"><a href="#Double-DQN" class="headerlink" title="Double DQN"></a>Double DQN</h1><p>由于DQN是一种基于Q learing的强化学习方法，那么在Q learning中存在着Qmax，Qmax会导致当前Q值得过估计(overestimate)。而Double DQN就是为了解决这个问题而提出来的。在实际问题中，如果你输出的DQN的Q值，你会发现，输出的Q值都十分大，这也就过估计导致的。</p>
<h2 id="Double-DQN-和-DQN的区别"><a href="#Double-DQN-和-DQN的区别" class="headerlink" title="Double DQN 和 DQN的区别"></a>Double DQN 和 DQN的区别</h2><p>我们知道DQN的神经网络部分看成一个最新神经网络(eval_net)和老神经网络(target_net)，他们有相同的结构，但是内部的参数更新存在时差。所以它的<strong>Q现实</strong>部分是：</p>
<p><img src="https://mofanpy.com/static/results/reinforcement-learning/4-5-1.png" alt="DNQ Q现实"></p>
<p>我们知道导致过估计的主要原因及时后面部分的Qmax，因为我们的神经网络预测Qmax本来就会有误差，每次也向着最大误差的<strong>Q现实</strong>进行改进神经网络，正式因为这个Qmax导致了过估计。所以Double DQN的办法就是引入另一个神经网络来打消一些最大误差的影响。而DQN中本来就有两个神经网络，我们可以利用其中一个神经网络。</p>
<p>对于Q估计的神经网络估计Q现实中Qmax(s_,a_)的最大动作值A，然后用这个被Q估计网络估计出的动作来选择Q现实中的Q（s_）。</p>
<p>简单来说，存在两个神经网络：eval_net(Q估计),target_net(Q现实):</p>
<p>对于DQN来说原本Q_next = max(Q_next(s_))</p>
<p>对于Double DQN则，Q_next = Q_next(s_,argmax(Q_eval(s_)))</p>
<p><img src="https://mofanpy.com/static/results/reinforcement-learning/4-5-2.png" alt="Double DQN"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/05/07/DQN-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/header.png">
      <meta itemprop="name" content="特大号的研究僧">
      <meta itemprop="description" content="禁鱼之地，塘主勿扰">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="特大号鲨鱼的池塘">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/05/07/DQN-1/" class="post-title-link" itemprop="url">DQN(Deep Q Network)---（1）</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-05-07 10:44:04" itemprop="dateCreated datePublished" datetime="2021-05-07T10:44:04+08:00">2021-05-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-08 11:37:55" itemprop="dateModified" datetime="2021-05-08T11:37:55+08:00">2021-05-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">强化学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="什么是DQN"><a href="#什么是DQN" class="headerlink" title="什么是DQN"></a>什么是DQN</h1><p><img src="https://mofanpy.com/static/results/ML-intro/DQN1.png" alt="强化学习和神经网络"></p>
<p>DQN（Deep Q Network）是一种用Q Learing和神经网络结合的一种强化学习的方法，相比于传统的Q Learning运用了神经网络的方法。</p>
<h1 id="神经网络的作用"><a href="#神经网络的作用" class="headerlink" title="神经网络的作用"></a>神经网络的作用</h1><p><img src="https://mofanpy.com/static/results/ML-intro/DQN2.png" alt="神经网络和Q learning"></p>
<p>对比于传统的Q Learning,DQN还额外附加了一个NN（Neural Network），它的通过输入的状态S得到各个不同的动作Actions的Q值<strong>（注意：Q值和奖励Reward不同）</strong>。</p>
<p>另一个作用，在DQN中存在一个存储器，存储了模型在自我学习过程中的S（当前状态），A（采取的某一个行动），R（该动作的奖励），S_（下一状态），（i.e，记作[S,A,R,S_]）。</p>
<h1 id="算法更新"><a href="#算法更新" class="headerlink" title="算法更新"></a>算法更新</h1><h2 id="Q-learning简介"><a href="#Q-learning简介" class="headerlink" title="Q-learning简介"></a>Q-learning简介</h2><p><img src="https://mofanpy.com/static/results/ML-intro/q3.png" alt="Q-learning简介"></p>
<p>简单说明一下传统的Q Learning：Q-Learing中的Q值分为两种Q_predict(Q估计值)和Q_target（Q现实值）,在上图中显示很清楚，Q现实值需要通过下一个状态(S_)和奖励R通过公式计算得到，而Q估计值是指当前转态S要采取某一个动作的值。<strong>（注意：一定要明白这一点，图中这个更新过程只是对Q(s1,a2)的更新）</strong><br>其中，<strong>gamma,alpha</strong>都是超参数（也就是自己设定的值）<br><img src="https://mofanpy.com/static/results/reinforcement-learning/2-1-1.png" alt="算法"></p>
<h2 id="DQN算法"><a href="#DQN算法" class="headerlink" title="DQN算法"></a>DQN算法</h2><p><img src="https://mofanpy.com/static/results/ML-intro/DQN3.png" alt="DQN算法"></p>
<p>有了Q Learning的一点基础后，相对来说，DQN只是多了一个卷积神经网络（或者其他神经网络），神经网络的作用上面已经说过了。DQN并没有像Q learning一样的Q值表（Q_table），但是它的Q值都是通过神经网络来计算得出的，如果确定了神经网络的参数，那么也就确定了各个状态S对应的动作Actions的Q值，也就相当于确定了一个Q值表。这样对于一个有大量状态和大量动作的模型来说就方便了太多太多。</p>
<h2 id="神经网络参数更新"><a href="#神经网络参数更新" class="headerlink" title="神经网络参数更新"></a>神经网络参数更新</h2><p><img src="https://mofanpy.com/static/results/ML-intro/DQN4.png" alt="参数更新"></p>
<p>注意，以上的Q值都是通过神经网络的过程计算得到的，并不是查询Q值表得到的。我们通过公式得到Q现实和Q估计，有了这两个数据，就能通过神经网络的方法来更新神经网络的参数，也就间接的相当于更新Q值表。</p>
<p><img src="https://mofanpy.com/static/results/reinforcement-learning/4-1-1.jpg" alt="DQN算法更新"></p>
<h1 id="DQN两大利器"><a href="#DQN两大利器" class="headerlink" title="DQN两大利器"></a>DQN两大利器</h1><p><img src="https://mofanpy.com/static/results/ML-intro/DQN5.png" alt="DNQ两大利器"></p>
<p>我们可以把DNQ想成两条主线，一条主线负责行动（例如在下围棋时，就是负责下围棋），另一条主线则是通过之前的动作来对神经网络进行学习训练。</p>
<p>Q learning 是一种 off-policy 离线学习法, 它能学习当前经历着的, 也能学习过去经历过的, 甚至是学习别人的经历. 所以每次 DQN 更新的时候, 我们都可以随机抽取一些之前的经历进行学习. 随机抽取这种做法打乱了经历之间的相关性, 也使得神经网络更新更有效率. Fixed Q-targets 也是一种打乱相关性的机理, 如果使用 fixed Q-targets, 我们就会在 DQN 中使用到两个结构相同但参数不同的神经网络, 预测 Q 估计 的神经网络具备最新的参数, 而预测 Q 现实 的神经网络使用的参数则是很久以前的. 有了这两种提升手段, DQN 才能在一些游戏中超越人类.</p>
<h1 id="简单例子描述"><a href="#简单例子描述" class="headerlink" title="简单例子描述"></a>简单例子描述</h1><p><img src="https://mofanpy.com/static/results/ML-intro/q3.png" alt="Q-learning简介"><br>我们以之前的Q learning为例，我们的目标是更新神经网络参数（在Q learning中为Q值表），假设我们已经记录了2个数据，为S1和S2就是图中这个表，我们将这两个状态输入当前的神经网络中，会得到一组全新的Q值表，这就是Q估计值，那么Q现实值是什么呢？</p>
<p>在我们的记录中也记录这某状态下采取某行动的奖励R，例如（S1，a2）状态的奖励，通过各个奖励R和S_的Q值，在通过图中公式，能够得到Q现实值，之后再更新神经网络的参数，这样一次也就完成了。<br>之后就是循环往复的过程。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>该文章只是个人简短理解，如果想了解更多和具体代码例子，建议点击下面链接</p>
<p><a target="_blank" rel="noopener" href="https://mofanpy.com/tutorials/machine-learning/reinforcement-learning/intro-DQN/" title="参考文献">https://mofanpy.com/tutorials/machine-learning/reinforcement-learning/intro-DQN/</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/05/05/Booklist2021/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/header.png">
      <meta itemprop="name" content="特大号的研究僧">
      <meta itemprop="description" content="禁鱼之地，塘主勿扰">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="特大号鲨鱼的池塘">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/05/05/Booklist2021/" class="post-title-link" itemprop="url">Booklist2021</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-05-05 17:33:33" itemprop="dateCreated datePublished" datetime="2021-05-05T17:33:33+08:00">2021-05-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-05-23 09:17:39" itemprop="dateModified" datetime="2021-05-23T09:17:39+08:00">2021-05-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E9%98%85%E8%AF%BB%E8%80%85/" itemprop="url" rel="index"><span itemprop="name">阅读者</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong>下面记录了我2021年的读书清单，读完一本之后才更新，直到2021年结束</strong></p>
<p><strong>希望我能通过这样的方式促进自己能多读书，读好书，好读书</strong></p>
<hr>
<h1 id="《人间失格》-太宰治"><a href="#《人间失格》-太宰治" class="headerlink" title="《人间失格》 太宰治"></a>《人间失格》 太宰治</h1><h2 id="Start-2021-4-12-具体我也不记得了"><a href="#Start-2021-4-12-具体我也不记得了" class="headerlink" title="Start:2021-4-12 (具体我也不记得了)"></a>Start:2021-4-12 (具体我也不记得了)</h2><p><img src="https://ebookg.com/storage/upload/files/000/26/20/71_cover_m.jpg" alt="《人间失格》"></p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><strong>“生而为人，我很抱歉”</strong>—–这个时代年轻人最喜欢调侃的经典丧名言</p>
<p>这是日本文豪太宰治的名句，也是太宰治的绝笔之作。太宰治——被村上春树誉为国民级作家，《人间失格》解剖了每个人的自我、孤独和迷惘，日本现代文学史的代表作品。主角大庭叶藏作为一个摸不清人类规则的“边缘人”，不断的自我放逐，逐渐“丧失了做人的资格”</p>
<h2 id="读后感"><a href="#读后感" class="headerlink" title="读后感"></a>读后感</h2><p>我只读完了《人间失格》大庭叶藏的部分，也就是三篇手记，这个小说的主角让我十分的反感，甚至恶心，用通俗的话来说，就是一副好牌，打得稀碎。叶藏从小就在伪装自己的内心，甚至把世界的人类分为两类，并不是男女两类，而是自己和除了自己的人，甚至他并不认为自己是人。他总是在刻意的讨好他人，装疯扮傻有意的迎合他人（包括他的父母）。其中一个片段把这一点体现的淋漓尽致：父亲问家人想要什么礼物，让大家写在清单上，叶藏一直是让父亲帮他带书籍，但是父亲这一次认为他是个小孩应该会喜欢老虎玩偶，这让叶藏感到十分的不安（其实叶藏自己也不知道想要什么，他只会考虑别人喜欢让他要什么），最终叶藏晚上偷偷的把玩偶写在清单上。</p>
<p>这种在乎他人看法到极致的人，活着很累，人应该大部分为了自己而活，但也应该体会他人的感受，毕竟人是社会群居生物，其中这个比例不同，造成了人的性格不同。</p>
<p>“生而为人，我很抱歉”，我希望这是一句警言提醒为自己，在我超乎寻常的为他人感受时，适当的放过自己，让自己在那时候变得自私一些。</p>
<ul>
<li><strong>“事实上，包括嘲笑我的人在内，人类不是在彼此的不信和猜忌中，照样丝毫没有将耶和华敬怀在心中，若无其事的生存着吗？”</strong></li>
</ul>
<h2 id="End：2021-4-20（大概时间）"><a href="#End：2021-4-20（大概时间）" class="headerlink" title="End：2021-4-20（大概时间）"></a>End：2021-4-20（大概时间）</h2><hr>
<h1 id="《朝闻道》刘慈欣"><a href="#《朝闻道》刘慈欣" class="headerlink" title="《朝闻道》刘慈欣"></a>《朝闻道》刘慈欣</h1><h2 id="Start：2021-4-28"><a href="#Start：2021-4-28" class="headerlink" title="Start：2021-4-28"></a>Start：2021-4-28</h2><p><img src="https://th.bing.com/th/id/Rcf1e372d6475f3d084dcbbe177f1b410?rik=ojK6exG4JcBVLg&riu=http://p7.qhmsg.com/dr/270_500_/t01add8f4dd4338673c.jpg?size=268x357&ehk=eLcMP1KMEerDlLzuj+4J3MQV4hksbhX1FpGliSpncdw=&risl=&pid=ImgRaw" alt="朝闻道"></p>
<h2 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h2><p>地核中的奇特生物，经过十万年的文明探索，终于突破了宇宙的屏障，却发现身处于另外一个更大的宇宙！天文学家研究出星星的运行规律，却发现星空与人类大佬的运行方式惊人一致！人类科学家即将发现宇宙的终极秘密，却被外星生命告知宇宙的真理吧必须用只自己的生命来交换！</p>
<p>（如果你是一个在生命道路上为了追求真理坚持不懈，永不放弃的人，但是最终被告知只需要献出你的生命，才能一窥真理的美，你会做什么样的选择）</p>
<p>大刘的《朝闻道》向我们展示了，那些追求真理的科学家的选择，各个国家元首的选择，以及普通人的反应。</p>
<h2 id="读后感-1"><a href="#读后感-1" class="headerlink" title="读后感"></a>读后感</h2><p>人的一生的意义是什么，作为一个理工科的研究生，我目前在做的事情，无非是利用科学的方法来解决一个有一个的实际问题，比如说，面对一个NP问题，如何用一种P的方法来得出一个更好的答案。如果有一天，有人问你，我能够为你提供一种完美的方法来解决这个问题，但是代价是和生命同等重要的东西（例如青春，朋友，亲人等等），对于现在的我来说我肯定是拒绝的，因为对于那个完美的解决方案，并不是最吸引我的东西，这也是我认为我不适合沉淀搞科学研究的原因吧！</p>
<p>假如把这个解决方案换成一个最吸引我的东西，你会去交换吗？我现在还是很难回答这个问题！</p>
<p>还是谈一谈小说本身吧，里面的主角丁仪是一个基础物理学家，一生的目标都是为了寻找宇宙大统一模型，最终被排险者（外星生命）告知只需要付出生命的代价，就能知道答案，但是这个答案不能告诉其他人。丁仪选择了付出生命而追求真理，像他一样的不只是基础物理学家，还有古生物学家，问了恐龙灭绝的原因，数学家，问了哥德巴赫猜想等，霍金博士问了宇宙的终极目的是什么，外星生命不能回答这个问题，霍金并没有成功的献出生命。我认为大刘的这个设定体现了一丝绝望中的希望，外星生命并不是神的存在，它们也有不知道的东西，和人类一样。</p>
<ul>
<li><strong>“对宇宙终极真理的追求是文明的最终目标和归宿”</strong></li>
<li><strong>“飞蛾扑火，它至少享受了短暂的光明”</strong></li>
</ul>
<h2 id="End-2021-5-3"><a href="#End-2021-5-3" class="headerlink" title="End:2021-5-3"></a>End:2021-5-3</h2><hr>
<h1 id="《一个人就一个人》-刘同"><a href="#《一个人就一个人》-刘同" class="headerlink" title="《一个人就一个人》 刘同"></a>《一个人就一个人》 刘同</h1><h2 id="Start-2021-5-4"><a href="#Start-2021-5-4" class="headerlink" title="Start:2021-5-4"></a>Start:2021-5-4</h2><p><img src="https://th.bing.com/th/id/Ra31839618ab8864995408a3213e4d06c?rik=rDlfSDv+j1Jb1g&riu=http://www.chinawriter.com.cn/NMediaFile/2020/0722/MAIN202007220836000270961459340.JPG&ehk=wGeBufEEK5sYUlPQViM295vGdi9LZRiqb3a+yA3B8fM=&risl=&pid=ImgRaw" alt="《一个人就一个人》"></p>
<h2 id="简介-2"><a href="#简介-2" class="headerlink" title="简介"></a>简介</h2><p>这是一本刘同的个人自传散文，讲述了一些作者生活中的小故事，个人感觉更像是一本意林短篇小说集；这本书最吸引人的地方是作者的笔法描述很生活随意化，通俗易懂，让人读的很畅快舒适。小说的一个个生活的小故事充满了刘同在平时生活中的一些想法，让人产生强烈的共鸣。</p>
<h2 id="读后感-2"><a href="#读后感-2" class="headerlink" title="读后感"></a>读后感</h2><p>5.10号晚上刚刚读完这本书，就立马来写读后感了，因为我害怕我忘记读完后的那种感觉。本以为全是刘同的个人日志分享，但其中也有两个他人的小故事，让人很感动。一个是关于爱情，两个人虽然互相有好感，而且都已经表达出来了，但是却不能在一起，因为男方有绝症。听起来很狗血，但还是让人羡慕这样的缘分和运气，遇见一个对的人，那么相处起来就不用小心翼翼，你能够依然做你自己，同时对方也会感到快乐幸福（感觉这个故事肯定是虚构的，故事叫<strong>“从不后悔遇见你”</strong>）。</p>
<p>另一个故事是关于母子亲情的，故事叫<strong>“友谊旅馆”</strong>，差点让我大晚上泪崩。为母则刚（并没有女子柔弱）。一个单亲妈妈既要扮演父亲又要扮演母亲，还要照顾孩子内心对父亲的疑问，承受孩子的不理解，实在是太难了，前天（5.9）刚刚过去的母亲节，我拜托了舅舅给妈妈订了一个蛋糕，这应该是第一次主动给她过母亲节，虽然没在家里看着她吃蛋糕，但是希望母亲能够幸福开心。</p>
<ul>
<li><strong>能看见就很满足，从未想过自己能拥有，直到被人提醒你连看的资格都没有。</strong></li>
<li><strong>年纪不是别人瞧不起你的理由，幼稚才是。</strong></li>
<li><strong>梦想是不需要分享的，只能自己埋头去做。</strong></li>
<li><strong>如果生活一成不变，那自己对待生活的态度就要改变。</strong></li>
<li><strong>我们都是成年人了，你不用对我撒谎、婉转，顾左右而言他，我们并不生气你的欺骗，我们只是生气你在浪费我的时间。</strong></li>
<li><strong>绝不和朋友发送经济往来。</strong></li>
</ul>
<p>就写到这吧！！！！</p>
<h2 id="End-2021-5-10"><a href="#End-2021-5-10" class="headerlink" title="End:2021-5-10##"></a>End:2021-5-10##</h2><hr>
<h1 id="《非暴力沟通》-美-马歇尔·卢森堡"><a href="#《非暴力沟通》-美-马歇尔·卢森堡" class="headerlink" title="《非暴力沟通》 [美]马歇尔·卢森堡#"></a>《非暴力沟通》 [美]马歇尔·卢森堡#</h1><h2 id="Start-2021-5-11"><a href="#Start-2021-5-11" class="headerlink" title="Start:2021-5-11"></a>Start:2021-5-11</h2><p><img src="https://img13.360buyimg.com/n1/jfs/t2023/299/1166228154/365325/48b4cb1/5641862fN6ba42b8d.jpg" alt="《非暴力沟通》"></p>
<h2 id="简介-3"><a href="#简介-3" class="headerlink" title="简介"></a>简介</h2><p>作为一个遵纪守法的好人，也许我们从来没有想过和“暴力”扯上关系。不过如果稍微留意一下现实生活中的谈话方式，并且用心体会各种谈话方式给我们的不同感受，我们一定会发现，有些话的确伤人！言语上的指责、嘲讽、否定、说教以及任意打断、拒不回应、随意出口的评价和结论给我们带来的情感和精神上的创伤，甚至比肉体的伤害更加令人痛苦。这些无心或有意的语言暴力让人与人变得冷漠、隔阂、敌视</p>
<h2 id="读一半感"><a href="#读一半感" class="headerlink" title="读一半感"></a>读一半感</h2><p>截止5月23日，读了一半，到了第八章。我还是不适合这种科普科学的书籍，感觉没有什么动力读下去。但是前面几章的内容，我还是挺有印象的，例如对于区分观察和评价的内容，当我们在和人对话的时候，评价的内容少于观察的内容，这样会让人更加舒服，过多的带有个人感情色彩的评价，可能会让人感到不舒服。</p>
<p>这本书目前就读到这吧，等有机会再把它阅读完。</p>
<ul>
<li><strong>我们不要将价值判断与道德评判混为一谈</strong></li>
<li><strong>真诚待人比委屈求全更为可贵</strong></li>
</ul>
<h2 id="End：2021-5-23"><a href="#End：2021-5-23" class="headerlink" title="End：2021-5-23"></a>End：2021-5-23</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="特大号的研究僧"
      src="/images/header.png">
  <p class="site-author-name" itemprop="name">特大号的研究僧</p>
  <div class="site-description" itemprop="description">禁鱼之地，塘主勿扰</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">5</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">特大号的研究僧</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
